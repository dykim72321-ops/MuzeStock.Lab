import re
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from typing import Dict, Any, List, Union


class AIAnalyzer:
    """
    OpenAI ì˜ì¡´ì„±ì„ ì œê±°í•˜ê³ , ìˆ˜ì¹˜ ë°ì´í„°ì™€ NLTK ê°ì„± ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ
    0.001ì´ˆ ë§Œì— í™•ì •ì (Deterministic) íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë™ì  í…œí”Œë¦¿ ì—”ì§„.
    (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ í´ë˜ìŠ¤ëª… AIAnalyzer ìœ ì§€: Algorithmic Intelligence)
    """

    def __init__(self):
        # Initialize NLTK VADER (ì˜¤í”„ë¼ì¸ ê°ì„± ë¶„ì„ê¸°)
        try:
            self.sia = SentimentIntensityAnalyzer()
        except LookupError:
            nltk.download("vader_lexicon", quiet=True)
            self.sia = SentimentIntensityAnalyzer()

    def _analyze_news_sentiment(
        self, news_list: Union[List[str], List[Dict], str]
    ) -> Dict[str, Any]:
        """ë‰´ìŠ¤ì˜ ê¸ì •/ë¶€ì • ìŠ¤ì½”ì–´ë¥¼ ì •ëŸ‰í™”í•˜ì—¬ ë°˜í™˜"""
        if not news_list:
            return {"score": 0.0, "status": "Neutral", "headlines": []}

        if isinstance(news_list, str):
            news_list = [news_list]

        total_compound = 0
        impactful_headlines = []

        for news in news_list:
            text = news.get("title", "") if isinstance(news, dict) else str(news)
            if not text:
                continue

            scores = self.sia.polarity_scores(text)
            compound = scores["compound"]
            total_compound += compound

            if abs(compound) > 0.3:
                sentiment_mark = "ğŸŸ¢" if compound > 0 else "ğŸ”´"
                impactful_headlines.append(f"{sentiment_mark} {text}")

        valid_count = len(news_list)
        avg_score = total_compound / valid_count if valid_count > 0 else 0.0

        status = (
            "Bullish"
            if avg_score > 0.15
            else ("Bearish" if avg_score < -0.15 else "Neutral")
        )

        return {
            "score": avg_score,
            "status": status,
            "headlines": impactful_headlines[:3],  # ìµœëŒ€ 3ê°œ í•µì‹¬ ê¸°ì‚¬ë§Œ ìœ ì§€
        }

    def _parse_indicators(self, ind_str: str) -> Dict[str, Any]:
        """ë¬¸ìì—´ë¡œ ì „ë‹¬ëœ ì§€í‘œì—ì„œ í•µì‹¬ ìˆ˜ì¹˜ë¥¼ ì¶”ì¶œí•˜ëŠ” íŒŒì„œ"""
        data = {"source": "Normal", "rsi": 50.0, "change": 0.0}

        if not ind_str or ind_str == "N/A":
            return data

        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ìˆ˜ì¹˜ ì¶”ì¶œ ([\d\.]+ ëŒ€ì‹  \d+(?:\.\d+)? ì‚¬ìš© â€” í›„í–‰ ë§ˆì¹¨í‘œ ë°©ì§€)
        if "Anomaly" in ind_str:
            data["source"] = "Anomaly"
        elif "Finviz Screened" in ind_str:
            data["source"] = "Finviz"

        rsi_match = re.search(r"RSI:\s*(\d+(?:\.\d+)?)", ind_str)
        if rsi_match:
            data["rsi"] = float(rsi_match.group(1))

        change_match = re.search(
            r"(?:Vol Change|Change):\s*([-\d]+(?:\.\d+)?)", ind_str
        )
        if change_match:
            data["change"] = float(change_match.group(1))

        return data

    async def analyze_stock(self, stock_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê·œì¹™ ê¸°ë°˜ DNA ìŠ¤ì½”ì–´ë§ ë° ë™ì  í…ìŠ¤íŠ¸ ìƒì„± (ë¹„ë™ê¸° ì²˜ë¦¬ êµ¬ì¡° ìœ ì§€)
        """
        ticker = stock_context.get("ticker", "UNKNOWN")
        news_data = self._analyze_news_sentiment(stock_context.get("news", []))
        ind_data = self._parse_indicators(stock_context.get("indicators", ""))

        # --- [1ë‹¨ê³„] DNA ìŠ¤ì½”ì–´ ì‚°ì¶œ ì‹œìŠ¤í…œ ---
        base_score = 50
        tags = []
        bull_factors = []
        bear_factors = []

        # 1. ìˆ˜ê¸‰ íƒì§€ ì†ŒìŠ¤ ê°€ì 
        if ind_data["source"] == "Anomaly":
            base_score += 15
            bull_factors.append("ê³ ë¦½ ìˆ²(Isolation Forest) ë¹„ì •ìƒ ìˆ˜ê¸‰ ìŠ¤í€´ì¦ˆ í¬ì°©.")
            tags.append("ğŸš¨ Anomaly Detected")
        elif ind_data["source"] == "Finviz":
            base_score += 5
            bull_factors.append("Finviz í€€íŠ¸ í•„í„°ë§ ì¡°ê±´ ì¶©ì¡±.")
            tags.append("ğŸ¯ Screened")

        # 2. RSI ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„
        rsi = ind_data["rsi"]
        if rsi < 30:
            base_score += 15
            bull_factors.append(
                f"RSI {rsi}ë¡œ ê·¹ë‹¨ì  ê³¼ë§¤ë„ êµ¬ê°„ ì§„ì… (ê¸°ìˆ ì  ë°˜ë“± ìœ ë ¥)."
            )
            tags.append("ğŸŒŠ Oversold")
        elif rsi > 70:
            base_score -= 15
            bear_factors.append(f"RSI {rsi}ë¡œ ê³¼ë§¤ìˆ˜ êµ¬ê°„ (ë‹¨ê¸° ì¡°ì • ë¦¬ìŠ¤í¬).")
            tags.append("ğŸ”¥ Overbought")
        else:
            bull_factors.append(f"RSI {rsi}ë¡œ ì•ˆì •ì ì¸ ì¶”ì„¸ ìœ ì§€ ì¤‘.")

        # 3. ë‰´ìŠ¤ ê°ì„± ìŠ¤ì½”ì–´ ë°˜ì˜ (-20 ~ +20 ì ìˆ˜ ë°˜ì˜)
        news_impact = int(news_data["score"] * 20)
        base_score += news_impact

        if news_data["status"] == "Bullish":
            bull_factors.append(
                f"ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì••ë„ì  ê¸ì • (Score: {news_data['score']:.2f})."
            )
            tags.append("ğŸ“ˆ Bullish News")
        elif news_data["status"] == "Bearish":
            bear_factors.append(
                f"ë¶€ì •ì  ë¯¸ë””ì–´ ì„¼í‹°ë¨¼íŠ¸ ê°ì§€ (Score: {news_data['score']:.2f})."
            )
            tags.append("ğŸ“‰ Bearish News")

        # ìµœì¢… ìŠ¤ì½”ì–´ ë³´ì • (0 ~ 100)
        final_score = max(0, min(100, base_score))

        # --- [2ë‹¨ê³„] ë™ì  ë¦¬í¬íŠ¸ ìƒì„± (String Formatting) ---
        if not bull_factors:
            bull_factors.append("ëšœë ·í•œ ìƒìŠ¹ ëª¨ë©˜í…€ì´ í¬ì°©ë˜ì§€ ì•ŠìŒ.")
        if not bear_factors:
            bear_factors.append("í˜„ì¬ êµ¬ê°„ì—ì„œ íŠ¹ë³„í•œ í•˜ë½ ë¦¬ìŠ¤í¬ ì§€í‘œ ì—†ìŒ.")

        reasoning = (
            f"[{ind_data['source']} íŠ¸ë™ ê¸°ë°˜ ë¶„ì„]\n"
            f"í•´ë‹¹ ì¢…ëª©ì€ ê¸°ìˆ ì , ìˆ˜ê¸‰ì , ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ ì¢…í•©í•œ ê²°ê³¼ DNA Score {final_score}ì ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. "
            f"RSI ì§€í‘œ({rsi})ì™€ NLTK ê°ì„± ì ìˆ˜({news_data['score']:.2f})ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚°ì¶œëœ í™•ì •ì (Deterministic) ìˆ˜ì¹˜ì…ë‹ˆë‹¤."
        )

        return {
            "dna_score": final_score,
            "bull_case": " ".join(bull_factors),
            "bear_case": " ".join(bear_factors),
            "reasoning_ko": reasoning,
            "tags": tags,  # í”„ë¡¬í”„íŠ¸ ëŒ€ì‹  í”„ë¡ íŠ¸ì—”ë“œ UI ë Œë”ë§ìš© ë°°ì—´ ì¶”ê°€
        }


# ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ë¸”ë¡
if __name__ == "__main__":
    import asyncio
    import json

    async def run_test():
        analyzer = AIAnalyzer()
        sample_context = {
            "ticker": "TSLA",
            "price": 250.0,
            "change": "+2.5%",
            "indicators": "Detection Source: Anomaly. Price: $250, RSI: 28.5, Change: 2.5%",
            "news": [
                "Tesla announces record breaking autonomous driving data",
                "Tesla factory upgrades completed",
            ],
        }
        result = await analyzer.analyze_stock(sample_context)
        print(
            f"âœ… Fast Algorithmic Analysis for TSLA:\n{json.dumps(result, indent=2, ensure_ascii=False)}"
        )

    asyncio.run(run_test())
